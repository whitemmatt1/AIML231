{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ba07c-c280-41e8-b9e6-63335ef78f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "from sklearn import datasets, neighbors\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=3) # limit precision when printing arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc14cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Decision Tree Classifier\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# To suppress boring warnings...\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the code block to load the csv files for training/testing.\n",
    "\n",
    "datasets  = {}\n",
    "\n",
    "df = pd.read_csv('./ionosphere_new.csv')\n",
    "X, y = df.drop('class', axis=1),  df['class']\n",
    "datasets[\"ionosphere\"] = (X,y)\n",
    "\n",
    "df = pd.read_csv('./steelplates_new.csv')\n",
    "X, y = df.drop('Class', axis=1),  df['Class']\n",
    "datasets[\"steelplates\"] = (X,y)\n",
    "\n",
    "df = pd.read_csv('./banknotes_new.csv')\n",
    "X, y = df.drop('Class', axis=1),  df['Class']\n",
    "datasets[\"banknotes\"] = (X,y)\n",
    "\n",
    "# TODO: set the number of trials required to evaluate the performance of a classifier.\n",
    "nTrials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a233bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def test(dataname, classifier, controlName, controlOptions, noXtics=False):\n",
    "    random.seed(100)  # Python's built-in random module\n",
    "    np.random.seed(100)\n",
    "    \n",
    "    X,y = datasets[dataname]\n",
    "\n",
    "    \n",
    "    org_ctl_options = controlOptions\n",
    "\n",
    "    scores = np.zeros(shape=(nTrials, len(controlOptions)))\n",
    "    for t in range(nTrials):\n",
    "        # TODO: perform train test split with the 50:50 ratio.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=t)\n",
    "\n",
    "        # TODO: standardize the value range of each feature in the dataset.\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        for i,option in enumerate(controlOptions):\n",
    "            model = classifier(**{controlName: option})\n",
    "            # TODO: perform model training.\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            scores[t,i] += model.score(X_test, y_test)\n",
    "\n",
    "    # Draw the box plots to visually display the model performance.\n",
    "    if controlName in ['alpha']: controlOptions = np.log10(controlOptions) # for semilogx\n",
    "    elif controlName in ['kernel']: controlOptions = [1, 2, 3, 4]\n",
    "    a = plt.boxplot(scores, positions=controlOptions, showfliers=False)\n",
    "    if noXtics:\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        if controlName in ['kernel']:\n",
    "            plt.xticks(controlOptions, org_ctl_options)\n",
    "        plt.xlabel(controlName)\n",
    "    plt.title(dataname + \" \" + type(model).__name__[:12])\n",
    "    print(\"{0:.2f} was the best {1} on {2}\".format(np.max(scores.mean(axis=0)),type(model).__name__[:12],dataname))\n",
    "    return(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b00a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSeveralDatas(classifier, controlName, options):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(131)\n",
    "    test(\"banknotes\", classifier, controlName, options)\n",
    "    plt.subplot(132)\n",
    "    test(\"steelplates\", classifier, controlName, options)\n",
    "    plt.subplot(133)\n",
    "    test(\"ionosphere\", classifier, controlName, options)\n",
    "    plt.savefig(type(classifier()).__name__ + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd57fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00 was the best KNeighborsCl on banknotes\n",
       "0.98 was the best KNeighborsCl on steelplates\n",
       "0.85 was the best KNeighborsCl on ionosphere\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testSeveralDatas(KNeighborsClassifier,\"n_neighbors\", range(1,6,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc07eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98 was the best DecisionTree on banknotes\n",
       "1.00 was the best DecisionTree on steelplates\n",
       "0.89 was the best DecisionTree on ionosphere\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testSeveralDatas(DecisionTreeClassifier,\"max_depth\", range(1,11,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b1dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99 was the best RandomForest on banknotes\n",
       "0.98 was the best RandomForest on steelplates\n",
       "0.93 was the best RandomForest on ionosphere\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testSeveralDatas(RandomForestClassifier, \"max_depth\", range(1,11,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea03a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00 was the best SVC on banknotes\n",
       "1.00 was the best SVC on steelplates\n",
       "0.94 was the best SVC on ionosphere\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testSeveralDatas(SVC, \"kernel\" , ['linear','poly', 'rbf', 'sigmoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This code block can be used to generate the ROC curves of the random forest classifier on one dataset. We set the maximum depth to 5.\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "# commented and uncommented the different datasets to display the ROC curves\n",
    "#X, y = datasets[\"ionosphere\"]\n",
    "#X, y = datasets[\"steelplates\"]\n",
    "X, y = datasets[\"banknotes\"]\n",
    "\n",
    "# TODO: perform train test split with the 50:50 ratio.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=100)\n",
    "\n",
    "# TODO: standardize the value range of each feature in the dataset.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train classifier\n",
    "rf_clf = RandomForestClassifier(max_depth=5)\n",
    "svc_clf = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "# TODO: perform model training.\n",
    "rf_clf.fit(X_train, y_train)\n",
    "svc_clf.fit(X_train, y_train)\n",
    "\n",
    "roc_disp = RocCurveDisplay.from_estimator(rf_clf, X_test, y_test)\n",
    "roc_disp = RocCurveDisplay.from_estimator(svc_clf, X_test, y_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
